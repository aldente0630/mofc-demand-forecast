{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edd19e-5716-4f22-b460-cd1b6c1bb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee08f63-ce34-4685-847e-2ec0d0066d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import kats.utils.time_series_parameter_tuning as tspt\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, \n",
    "    mean_squared_error, \n",
    "    mean_tweedie_deviance,\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from kats.consts import SearchMethodEnum, TimeSeriesData\n",
    "from kats.models.prophet import ProphetModel, ProphetParams\n",
    "from kats.utils.backtesters import BackTesterSimple\n",
    "from kats.utils.parameter_tuning_utils import (\n",
    "    get_default_prophet_parameter_search_space,\n",
    "    get_default_var_parameter_search_space,\n",
    ")\n",
    "from kats.models.var import VARModel, VARParams\n",
    "from pandarallel import pandarallel\n",
    "from utils.evaluation import calc_eval_metric, WRMSSEEvaluator\n",
    "from utils.misc import dump_pickle, load_pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc727fbb-1fed-4b30-a77d-b9cc710335e4",
   "metadata": {},
   "source": [
    "The Kaggle dataset was saved in the local directory `~/data/mofc-demand-forecast` in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccdac0-f93d-4b8d-bbfc-e9c196790910",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/mofc-demand-forecast\"\n",
    "MODEL_PATH = \"models\"\n",
    "TUNE_PARAMS = True\n",
    "\n",
    "calendar = pd.read_csv(os.path.join(DATA_PATH, \"calendar.csv\"))\n",
    "selling_prices = pd.read_csv(os.path.join(DATA_PATH, \"sell_prices.csv\"))\n",
    "# df_train_valid = pd.read_csv(os.path.join(DATA_PATH, \"sales_train_validation.csv\"))\n",
    "df_train_eval = pd.read_csv(os.path.join(DATA_PATH, \"sales_train_evaluation.csv\"))\n",
    "# sample_submission = pd.read_csv(os.path.join(DATA_PATH, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133e0eb-80df-4d60-9fac-c3b4d223e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_names = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n",
    "date_names = [\"d_\" + str(i) for i in range(1, 1942)]\n",
    "all_ids = df_train_eval[\"id\"].unique()\n",
    "test_steps = 28\n",
    "\n",
    "valid_sample_ratio = 0.01\n",
    "test_sample_ratio = 0.1\n",
    "\n",
    "if valid_sample_ratio == 1.0:\n",
    "    valid_sampled_ids = all_ids\n",
    "else:\n",
    "    valid_sampled_ids = np.random.choice(\n",
    "        all_ids, round(valid_sample_ratio * len(all_ids)), replace=False\n",
    "    ).tolist()\n",
    "\n",
    "if test_sample_ratio == 1.0:\n",
    "    test_sampled_ids = all_ids\n",
    "else:\n",
    "    test_sampled_ids = np.random.choice(\n",
    "        all_ids, round(test_sample_ratio * len(all_ids)), replace=False\n",
    "    ).tolist()\n",
    "\n",
    "print(\n",
    "    f\"{len(valid_sampled_ids)} out of {len(all_ids)} IDs were selected for validation, and {len(test_sampled_ids)} out of {len(all_ids)} IDs were selected for testing.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab57d5-24c8-431d-861f-c7e0e5ba6391",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f782f-1342-45fb-ba56-c7d2c508b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_eval[key_names[:1] + date_names[:-test_steps]]\n",
    "df_train = df_train.set_index(\"id\").T.reset_index()\n",
    "date_dict = calendar[[\"date\", \"d\"]].set_index(\"d\").to_dict()[\"date\"]\n",
    "df_train[\"index\"] = df_train[\"index\"].replace(date_dict)\n",
    "df_train.columns = [\"time\"] + df_train.columns[1:].tolist()\n",
    "df_train.index.name = \"\"\n",
    "\n",
    "series_time = df_train[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b877f48-12f0-4c90-bcca-8cc8b436fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = calendar[[\"event_name_1\", \"event_name_2\"]].dropna(how=\"all\").index\n",
    "holidays = calendar.loc[indices, [\"date\", \"event_name_1\", \"event_name_2\"]]\n",
    "holidays = (\n",
    "    pd.melt(\n",
    "        holidays,\n",
    "        id_vars=\"date\",\n",
    "        value_vars=[\"event_name_1\", \"event_name_2\"],\n",
    "        value_name=\"holiday\",\n",
    "    )\n",
    "    .dropna()[[\"holiday\", \"date\"]]\n",
    "    .sort_values(\"date\")\n",
    ")\n",
    "holidays.index = range(holidays.shape[0])\n",
    "holidays.columns = [\"holiday\", \"ds\"]\n",
    "holidays[\"lower_window\"] = 0\n",
    "holidays[\"upper_window\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2248b7d8-a2e2-4251-a4ed-f204cd8a7b12",
   "metadata": {},
   "source": [
    "# Baseline: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26597582-1749-4af2-b3e0-6e2e6bc6ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df_train_eval.set_index(\"id\").loc[test_sampled_ids].reset_index()\n",
    "df_train_sampled = df_sampled.loc[:, key_names + date_names[:-test_steps]]\n",
    "df_test_sampled = df_sampled.loc[:, date_names[-test_steps:]]\n",
    "\n",
    "evaluator = WRMSSEEvaluator(df_train_sampled, df_test_sampled, calendar, selling_prices, test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e1343-f160-44d8-aa8e-cd94d34c15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sampled = pd.DataFrame(\n",
    "    np.repeat(\n",
    "        df_train_sampled[date_names[:-test_steps]].mean(axis=1).values.reshape(-1, 1),\n",
    "        test_steps,\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "df_pred_sampled.columns = df_test_sampled.columns\n",
    "wrmsse = evaluator.score(df_pred_sampled)\n",
    "eval_metrics = calc_eval_metric(df_test_sampled, df_pred_sampled)\n",
    "\n",
    "print(f\"Mean Method WRMSSE: {wrmsse:.6f}\")\n",
    "display(eval_metrics.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582a5ac-b65b-4bfb-9aa4-6d5f89e47efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sampled = pd.DataFrame(\n",
    "    np.repeat(\n",
    "        df_train_sampled[date_names[-test_steps - 1 : -test_steps]].values,\n",
    "        test_steps,\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "df_pred_sampled.columns = df_test_sampled.columns\n",
    "wrmsse = evaluator.score(df_pred_sampled)\n",
    "eval_metrics = calc_eval_metric(df_test_sampled, df_pred_sampled)\n",
    "\n",
    "print(f\"Naive Method WRMSSE: {wrmsse:.6f}\")\n",
    "display(eval_metrics.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f17d257-1abf-4ac5-bd41-f3f9b781453a",
   "metadata": {},
   "source": [
    "# Prophet: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab9759-b854-44f2-86f3-92a7f7f27048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(df, steps, params, include_history=False):\n",
    "    sales_ts = TimeSeriesData(df=df, sort_by_time=True, time_col_name=\"time\")\n",
    "\n",
    "    model = ProphetModel(data=sales_ts, params=params)\n",
    "    model.fit()\n",
    "\n",
    "    forecast = model.predict(\n",
    "        steps=steps,\n",
    "        include_history=include_history,\n",
    "        freq=\"D\",\n",
    "    )\n",
    "\n",
    "    return model, forecast\n",
    "    \n",
    "\n",
    "def get_func(prophet_params, train_index, test_index):\n",
    "    def calc_model_loss(y):\n",
    "        global series_time\n",
    "        eps = 1e-6\n",
    "        \n",
    "        df = pd.concat([series_time, y], axis=1)\n",
    "        df.columns = [\"time\", \"y\"]\n",
    "        \n",
    "        model, forecast = fit_and_predict(\n",
    "            df.loc[train_index, :], \n",
    "            len(test_index),\n",
    "            prophet_params\n",
    "        )\n",
    "\n",
    "        y_true = df[\"y\"].loc[test_index].values\n",
    "        y_pred = forecast[\"fcst\"].values\n",
    "        y_pred = np.where(y_pred < eps, eps, y_pred)\n",
    "\n",
    "        return mean_tweedie_deviance(y_true, y_pred, power=1.5)\n",
    "\n",
    "    return calc_model_loss\n",
    "\n",
    "\n",
    "def evaluation_function(params):\n",
    "    prophet_params = ProphetParams(\n",
    "        n_changepoints=params[\"n_changepoints\"],\n",
    "        changepoint_range=params[\"changepoint_range\"],\n",
    "        yearly_seasonality=\"auto\",\n",
    "        weekly_seasonality=\"auto\",\n",
    "        daily_seasonality=\"auto\",\n",
    "        holidays=holidays,\n",
    "        holidays_prior_scale=params[\"holidays_prior_scale\"],\n",
    "        seasonality_mode=params[\"seasonality_mode\"],\n",
    "        seasonality_prior_scale=params[\"seasonality_prior_scale\"],\n",
    "        changepoint_prior_scale=params[\"changepoint_prior_scale\"],\n",
    "        floor=0.0,\n",
    "    )\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    losses = []\n",
    "\n",
    "    for train_index, test_index in tscv.split(df_train):\n",
    "        evaluate = get_func(prophet_params, train_index, test_index)\n",
    "        res = df_train[valid_sampled_ids].apply(evaluate)\n",
    "        losses.append(res.mean())\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef87ca2f-d982-459d-9ccb-1b8e23a5145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "if TUNE_PARAMS:\n",
    "    parameters = get_default_prophet_parameter_search_space()\n",
    "    parameters = parameters[:1] + parameters[4:]\n",
    "    parameters[0][\"values\"] = parameters[0][\"values\"] + [25.0, 50.0, 100.0]\n",
    "    parameters.append(\n",
    "        {\n",
    "            \"name\": \"n_changepoints\",\n",
    "            \"type\": \"choice\",\n",
    "            \"value_type\": \"int\",\n",
    "            \"values\": [5, 10, 25, 50, 100],\n",
    "            \"is_ordered\": True,\n",
    "        }\n",
    "    )\n",
    "    parameters.append(\n",
    "        {\n",
    "            \"name\": \"holidays_prior_scale\",\n",
    "            \"type\": \"choice\",\n",
    "            \"value_type\": \"float\",\n",
    "            \"values\": [0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5, 10.0, 25.0, 50.0, 100.0],\n",
    "            \"is_ordered\": True,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    parameter_tuner = tspt.SearchMethodFactory.create_search_method(\n",
    "        parameters=parameters,\n",
    "        evaluation_function=evaluation_function,\n",
    "        bootstrap_size=10,\n",
    "        selected_search_method=SearchMethodEnum.BAYES_OPT,\n",
    "        seed=42,\n",
    "        multiprocessing=True,\n",
    "    )\n",
    "\n",
    "    parameter_tuner.generate_evaluate_new_parameter_values(\n",
    "        evaluation_function=evaluation_function,\n",
    "        arm_count=20,\n",
    "    )\n",
    "\n",
    "    tuning_results = parameter_tuner.list_parameter_value_scores()\n",
    "    \n",
    "    os.makedirs(os.path.join(MODEL_PATH, \"prophet\"), exist_ok=True)\n",
    "    dump_pickle(os.path.join(MODEL_PATH, \"prophet\", \"prophet_tuning_results.pkl\"), tuning_results)\n",
    "\n",
    "else:\n",
    "    tuning_results = load_pickle(os.path.join(MODEL_PATH, \"prophet\", \"prophet_tuning_results.pkl\"))\n",
    "\n",
    "best_params = tuning_results.loc[tuning_results[\"mean\"].argmin(), \"parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677ecef-86a9-408f-b98d-e9ce07fd48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.concat(\n",
    "    [pd.json_normalize(tuning_results[\"parameters\"]), tuning_results[\"mean\"]],\n",
    "    axis=1,\n",
    ")\n",
    "summary.columns = summary.columns[:-1].tolist() + [\"loss\"]\n",
    "\n",
    "display(summary.sort_values(\"loss\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156083e1-d7f1-4856-ad72-03cec248d9a3",
   "metadata": {},
   "source": [
    "# Prophet: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c6a03-dda2-486d-bb9b-682f4802d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_params = ProphetParams(\n",
    "    n_changepoints=best_params[\"n_changepoints\"],\n",
    "    changepoint_range=best_params[\"changepoint_range\"],\n",
    "    yearly_seasonality=\"auto\",\n",
    "    weekly_seasonality=\"auto\",\n",
    "    daily_seasonality=\"auto\",\n",
    "    holidays=holidays,\n",
    "    seasonality_mode=best_params[\"seasonality_mode\"],\n",
    "    seasonality_prior_scale=best_params[\"seasonality_prior_scale\"],\n",
    "    holidays_prior_scale=best_params[\"holidays_prior_scale\"],\n",
    "    changepoint_prior_scale=best_params[\"changepoint_prior_scale\"],\n",
    "    floor=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bafecb1-90c1-41c8-8d08-d7c76bca8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(y):\n",
    "    global series_time\n",
    "    global train_percentage\n",
    "    global test_percentage\n",
    "    global error_methods\n",
    "    global prophet_params\n",
    "\n",
    "    df = pd.concat([series_time, y], axis=1)\n",
    "    df.columns = [\"time\", \"y\"]\n",
    "    \n",
    "    sales_ts = TimeSeriesData(df=df, sort_by_time=True, time_col_name=\"time\")\n",
    "    \n",
    "    backtester = BackTesterSimple(\n",
    "        train_percentage=train_percentage,\n",
    "        test_percentage=test_percentage, \n",
    "        error_methods=error_methods,\n",
    "        data=sales_ts,\n",
    "        params=prophet_params,\n",
    "        model_class=ProphetModel,\n",
    "    )\n",
    "    \n",
    "    backtester.run_backtest()\n",
    "    \n",
    "    return list(backtester.errors.values())\n",
    "\n",
    "\n",
    "def predict(y):\n",
    "    global series_time\n",
    "    global test_steps\n",
    "    global prophet_params\n",
    "\n",
    "    df = pd.concat([series_time, y], axis=1)\n",
    "    df.columns = [\"time\", \"y\"]\n",
    "    \n",
    "    model, forecast = fit_and_predict(df, test_steps, prophet_params)\n",
    "\n",
    "    y_pred = forecast[\"fcst\"].values\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ab39a-308d-40a7-9d79-56fd528a5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "pandarallel.initialize(\n",
    "    nb_workers=multiprocessing.cpu_count() - 1,\n",
    "    progress_bar=False,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "train_percentage = 100 * len(date_names) / (len(date_names) + test_steps)\n",
    "test_percentage = 100 - train_percentage\n",
    "error_methods = [\"mape\", \"smape\", \"mae\", \"mase\", \"mse\", \"rmse\"]\n",
    "\n",
    "backtests = df_train[test_sampled_ids].parallel_apply(backtest, result_type=\"reduce\")\n",
    "\n",
    "parsed = dict()\n",
    "for index, values in backtests.iteritems():\n",
    "    parsed[index] = list(values)\n",
    "backtests = pd.DataFrame(parsed, index=error_methods).T\n",
    "\n",
    "display(backtests.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2609843-ac91-49e3-b106-be40f84f6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "predictions = df_train[test_sampled_ids].parallel_apply(predict, result_type=\"reduce\")\n",
    "\n",
    "parsed = dict()\n",
    "for index, values in predictions.iteritems():\n",
    "    parsed[index] = list(values)\n",
    "predictions = pd.DataFrame(parsed).iloc[-test_steps:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cb72a-8e9a-4c6d-97fe-ec3df4da9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sampled = predictions.T\n",
    "df_pred_sampled = df_pred_sampled.loc[test_sampled_ids]\n",
    "df_pred_sampled.columns = df_test_sampled.columns\n",
    "df_pred_sampled.index = range(len(test_sampled_ids))\n",
    "\n",
    "wrmsse = evaluator.score(df_pred_sampled)\n",
    "eval_metrics = calc_eval_metric(df_test_sampled, df_pred_sampled)\n",
    "\n",
    "print(f\"Propeht WRMSSE: {wrmsse:.6f}\")\n",
    "display(eval_metrics.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79803e83-62c7-4804-98a0-f2acf494a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(source, test_steps, plot_id=None, model_name=None, start_date=None):\n",
    "    if start_date is not None:\n",
    "        source = source[source[\"time\"] >= start_date]\n",
    "\n",
    "    points = (\n",
    "        alt.Chart(source)\n",
    "        .mark_circle(size=10.0, color=\"#000000\")\n",
    "        .encode(\n",
    "            x=alt.X(\"time:T\", axis=alt.Axis(title=\"Date\")),\n",
    "            y=alt.Y(\"y\", axis=alt.Axis(title=\"Demand\")),\n",
    "            tooltip=[\"time:T\", \"y:Q\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    line = (\n",
    "        alt.Chart(source)\n",
    "        .mark_line(size=1.0, color=\"#4267B2\")\n",
    "        .encode(\n",
    "            x=\"time:T\",\n",
    "            y=\"fcst\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    band = (\n",
    "        alt.Chart(source)\n",
    "        .mark_area(opacity=0.25, color=\"#4267B2\")\n",
    "        .encode(\n",
    "            x=\"time:T\",\n",
    "            y=\"fcst_lower\",\n",
    "            y2=\"fcst_upper\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    rule = (\n",
    "        alt.Chart(source[[\"time\"]].iloc[-test_steps : -test_steps + 1])\n",
    "        .mark_rule(size=1.0, color=\"#FF0000\", strokeDash=[2, 2])\n",
    "        .encode(x=\"time:T\")\n",
    "    )\n",
    "\n",
    "    title = \"Demand Forecast\"\n",
    "    if plot_id is not None:\n",
    "        title += f\" for '{plot_id}'\"\n",
    "    if model_name is not None:\n",
    "        title = f\"{model_name}: \" + title\n",
    "\n",
    "    return (points + line + band + rule).properties(title=title, width=1000, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e8333-7ff3-43ca-a6c7-86df99a6b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_indices = [2, 4, 8]\n",
    "plots = []\n",
    "\n",
    "for plot_index in plot_indices:\n",
    "    plot_id = test_sampled_ids[plot_index]\n",
    "\n",
    "    df = df_train[[\"time\"] + [plot_id]]\n",
    "    df.columns = [\"time\", \"y\"]\n",
    "\n",
    "    model, forecast = fit_and_predict(\n",
    "        df, test_steps, prophet_params, include_history=True\n",
    "    )\n",
    "\n",
    "    y = (df_train_eval[df_train_eval[\"id\"] == plot_id].loc[:, date_names]).T\n",
    "    y.columns = [\"y\"]\n",
    "    y = calendar.merge(y, left_on=\"d\", right_index=True)[[\"date\", \"y\"]]\n",
    "    y[\"time\"] = pd.to_datetime(y[\"date\"])\n",
    "\n",
    "    source = y.merge(forecast, how=\"left\").drop([\"date\"], axis=1)\n",
    "    p = plot_forecast(\n",
    "        source, test_steps, plot_id=plot_id, model_name=\"Prophet\", start_date=\"2015-05-23\"\n",
    "    )\n",
    "    \n",
    "    plots.append(p)\n",
    "    \n",
    "alt.VConcatChart(vconcat=plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2dd827-8bd8-44e5-8f2a-f8dae690e7ca",
   "metadata": {},
   "source": [
    "# VAR: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5375ed-6a46-40e0-b8e8-c53b93140c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "var_params = VARParams(trend=\"ct\")\n",
    "\n",
    "df = pd.concat([series_time, df_train[test_sampled_ids]], axis=1)\n",
    "sales_ts = TimeSeriesData(\n",
    "    df=df, sort_by_time=True, time_col_name=\"time\"\n",
    ")\n",
    "\n",
    "model = VARModel(data=sales_ts, params=var_params)\n",
    "model.fit()\n",
    "\n",
    "forecast = model.predict(\n",
    "    steps=test_steps,\n",
    "    include_history=True,\n",
    "    freq=\"D\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3122fb3b-8849-4508-86ac-d7b9a38bfdf7",
   "metadata": {},
   "source": [
    "* The backtesters module currently only supports univariate, so it was not used for *VAR*, a multivariate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559654c-59c0-4b6f-8d9f-cf793c54b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = dict()\n",
    "for test_sampled_id in test_sampled_ids:\n",
    "    parsed[test_sampled_id] = (\n",
    "        forecast[test_sampled_id].to_dataframe()[\"fcst\"].values.tolist()\n",
    "    )\n",
    "predictions = pd.DataFrame(parsed).iloc[-test_steps:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644d7cd-e950-4e66-81c4-6ee547e91db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_sampled = predictions.T\n",
    "df_pred_sampled = df_pred_sampled.loc[test_sampled_ids]\n",
    "df_pred_sampled.columns = df_test_sampled.columns\n",
    "df_pred_sampled.index = range(len(test_sampled_ids))\n",
    "\n",
    "wrmsse = evaluator.score(df_pred_sampled)\n",
    "eval_metrics = calc_eval_metric(df_test_sampled, df_pred_sampled)\n",
    "\n",
    "print(f\"VAR WRMSSE: {wrmsse:.6f}\")\n",
    "display(eval_metrics.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd010aa8-bbb4-402c-9ec6-fd2074d2e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_indices = [2, 4, 8]\n",
    "plots = []\n",
    "\n",
    "for plot_index in plot_indices:\n",
    "    plot_id = test_sampled_ids[plot_index]\n",
    "\n",
    "    y = (df_train_eval[df_train_eval[\"id\"] == plot_id].loc[:, date_names]).T\n",
    "    y.columns = [\"y\"]\n",
    "    y = calendar.merge(y, left_on=\"d\", right_index=True)[[\"date\", \"y\"]]\n",
    "    y[\"time\"] = pd.to_datetime(y[\"date\"])\n",
    "\n",
    "    source = y.merge(forecast[plot_id].to_dataframe(), how=\"left\").drop([\"date\"], axis=1)\n",
    "\n",
    "    p = plot_forecast(source, test_steps, plot_id=plot_id, model_name=\"VAR\", start_date=\"2015-05-23\")\n",
    "    plots.append(p)\n",
    "    \n",
    "alt.VConcatChart(vconcat=plots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
